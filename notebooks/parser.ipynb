{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Внешние отраслевые источники"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## https://b1.ru/b1-surveys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "import hashlib\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "def get_soup(link):\n",
    "    HEADERS = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36\"\n",
    "    }\n",
    "    soup = None\n",
    "    response = requests.get(link, headers=HEADERS)\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    else:\n",
    "        print(f\"Ошибка запроса: {response.status_code}\")\n",
    "    return soup\n",
    "\n",
    "\n",
    "URL = 'https://b1.ru/'\n",
    "SURVEYS_URL = URL + 'b1-surveys/'\n",
    "\n",
    "\n",
    "soup = get_soup(SURVEYS_URL)\n",
    "pagination = soup.find('div', class_='pagination')\n",
    "page_links = [a['href'] for a in pagination.find_all('a') if '?PAGEN_2=' in a['href']]\n",
    "last_page = max([int(a.split('?PAGEN_2=')[-1]) for a in page_links])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [14:37<00:00, 125.40s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "analytics = []\n",
    "for i in tqdm(range(1, last_page + 1)):\n",
    "    soup = get_soup(SURVEYS_URL + '?PAGEN_2=' + str(i))\n",
    "    time.sleep(1)\n",
    "    analytics_block = {}\n",
    "    for block in soup.find_all('div', class_=re.compile(r\"^news-block__gridItem triangleWrap--hover\")):\n",
    "        if block:\n",
    "            link = block['src-href']\n",
    "            if not 'services' in link:\n",
    "                analytics_block['link'] = link\n",
    "                analytics_block['date'] = block.find('p', class_='news-block__date').text\n",
    "                analytics_block['name'] = block.find('h2', class_='news-block__title').text\n",
    "                analytics_block['name_en'] = link.strip().strip('/').split('/')[-1]\n",
    "                \n",
    "                time.sleep(1)\n",
    "                analytics_soup = get_soup(URL + link)\n",
    "                tags_block = analytics_soup.find('div', class_=re.compile(r\"tezis-list-block__tags\"))\n",
    "                if tags_block:\n",
    "                    analytics_block['tags'] = [a.text for a in tags_block.find_all('a', class_=re.compile(r\"tag\"))]\n",
    "                else:\n",
    "                    analytics_block['tags'] = []\n",
    "                \n",
    "                analytics_block['text'] = '\\n'.join([re.sub(r\"\\n+\", \"\\n\", x.text) for x in analytics_soup.find('main').find('section').find_next_siblings()])\n",
    "                analytics_block['pdf_links'] = [f'{URL}{a['href']}' for a in analytics_soup.find_all('a', href=True) if a['href'].endswith('.pdf')]\n",
    "                analytics_block['pdf_links'].append(f'{URL}local/assets/surveys/{analytics_block['name_en']}.pdf')\n",
    "                \n",
    "                pdfs_content = []\n",
    "                pdfs_names = []\n",
    "                for url in analytics_block['pdf_links']:\n",
    "                    response = requests.get(url, stream=True)\n",
    "                    if response.status_code == 200:\n",
    "                        pdf_name = url.strip().strip('/').split('/')[-1]\n",
    "                        pdf_content = response.content\n",
    "                        if pdf_name not in pdfs_names:\n",
    "                            pdfs_names.append(pdf_name)\n",
    "                            pdfs_content.append({\"name\": pdf_name, \"content\": pdf_content})\n",
    "                analytics_block['pdfs'] = pdfs_content\n",
    "                analytics.append(analytics_block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('analytics.pkl', 'wb') as f:\n",
    "    pickle.dump(analytics, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import pdfplumber\n",
    "import tempfile\n",
    "\n",
    "\n",
    "def extract_table(pdf_path, page_num, table_num):\n",
    "    pdf = pdfplumber.open(pdf_path)\n",
    "    table_page = pdf.pages[page_num]\n",
    "    table = table_page.extract_tables()[table_num]\n",
    "    return table\n",
    "\n",
    "\n",
    "def table_converter(table):\n",
    "    table_string = ''\n",
    "    for row_num in range(len(table)):\n",
    "        row = table[row_num]\n",
    "        # Удаляем разрыв строки из текста с переносом\n",
    "        cleaned_row = [item.replace('\\n', ' ') if item is not None and '\\n' in item else 'None' if item is None else item for item in row]\n",
    "        # Преобразуем таблицу в строку\n",
    "        table_string+=('|'+'|'.join(cleaned_row)+'|'+'\\n')\n",
    "    # Удаляем последний разрыв строки\n",
    "    table_string = table_string[:-1]\n",
    "    return table_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tempfile.NamedTemporaryFile() as temp_file:\n",
    "    temp_file.write(analytics[0]['pdfs'][0]['content'])\n",
    "    temp_file_path = temp_file.name\n",
    "    pdfReaded = PyPDF2.PdfReader(temp_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PyPDF2._reader.PdfReader at 0x10983e990>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdfReaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'bytes' object has no attribute 'seek'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pdfReaded \u001b[38;5;241m=\u001b[39m \u001b[43mPyPDF2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPdfReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43manalytics\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpdfs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/projects/industry_analytics_parser/.venv/lib/python3.13/site-packages/PyPDF2/_reader.py:319\u001b[0m, in \u001b[0;36mPdfReader.__init__\u001b[0;34m(self, stream, strict, password)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(stream, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fh:\n\u001b[1;32m    318\u001b[0m         stream \u001b[38;5;241m=\u001b[39m BytesIO(fh\u001b[38;5;241m.\u001b[39mread())\n\u001b[0;32m--> 319\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream \u001b[38;5;241m=\u001b[39m stream\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_override_encryption \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/projects/industry_analytics_parser/.venv/lib/python3.13/site-packages/PyPDF2/_reader.py:1414\u001b[0m, in \u001b[0;36mPdfReader.read\u001b[0;34m(self, stream)\u001b[0m\n\u001b[1;32m   1413\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mread\u001b[39m(\u001b[38;5;28mself\u001b[39m, stream: StreamType) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1414\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_basic_validation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1415\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_find_eof_marker(stream)\n\u001b[1;32m   1416\u001b[0m     startxref \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_find_startxref_pos(stream)\n",
      "File \u001b[0;32m~/Documents/projects/industry_analytics_parser/.venv/lib/python3.13/site-packages/PyPDF2/_reader.py:1453\u001b[0m, in \u001b[0;36mPdfReader._basic_validation\u001b[0;34m(self, stream)\u001b[0m\n\u001b[1;32m   1451\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_basic_validation\u001b[39m(\u001b[38;5;28mself\u001b[39m, stream: StreamType) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1452\u001b[0m     \u001b[38;5;66;03m# start at the end:\u001b[39;00m\n\u001b[0;32m-> 1453\u001b[0m     \u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseek\u001b[49m(\u001b[38;5;241m0\u001b[39m, os\u001b[38;5;241m.\u001b[39mSEEK_END)\n\u001b[1;32m   1454\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream\u001b[38;5;241m.\u001b[39mtell():\n\u001b[1;32m   1455\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m EmptyFileError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot read an empty file\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'bytes' object has no attribute 'seek'"
     ]
    }
   ],
   "source": [
    "pdfReaded = PyPDF2.PdfReader(analytics[0]['pdfs'][0]['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ini"
    }
   },
   "outputs": [],
   "source": [
    "pdf_path = 'OFFER 3.pdf'\n",
    "\n",
    "# создаём объект файла PDF\n",
    "pdfFileObj = open(pdf_path, 'rb')\n",
    "# создаём объект считывателя PDF\n",
    "pdfReaded = PyPDF2.PdfReader(pdfFileObj)\n",
    "\n",
    "# Создаём словарь для извлечения текста из каждого изображения\n",
    "text_per_page = {}\n",
    "# Извлекаем страницы из PDF\n",
    "for pagenum, page in enumerate(extract_pages(pdf_path)):\n",
    "    \n",
    "    # Инициализируем переменные, необходимые для извлечения текста со страницы\n",
    "    pageObj = pdfReaded.pages[pagenum]\n",
    "    page_text = []\n",
    "    line_format = []\n",
    "    text_from_images = []\n",
    "    text_from_tables = []\n",
    "    page_content = []\n",
    "    # Инициализируем количество исследованных таблиц\n",
    "    table_num = 0\n",
    "    first_element= True\n",
    "    table_extraction_flag= False\n",
    "    # Открываем файл pdf\n",
    "    pdf = pdfplumber.open(pdf_path)\n",
    "    # Находим исследуемую страницу\n",
    "    page_tables = pdf.pages[pagenum]\n",
    "    # Находим количество таблиц на странице\n",
    "    tables = page_tables.find_tables()\n",
    "\n",
    "\n",
    "    # Находим все элементы\n",
    "    page_elements = [(element.y1, element) for element in page._objs]\n",
    "    # Сортируем все элементы по порядку нахождения на странице\n",
    "    page_elements.sort(key=lambda a: a[0], reverse=True)\n",
    "\n",
    "    # Находим элементы, составляющие страницу\n",
    "    for i,component in enumerate(page_elements):\n",
    "        # Извлекаем положение верхнего края элемента в PDF\n",
    "        pos= component[0]\n",
    "        # Извлекаем элемент структуры страницы\n",
    "        element = component[1]\n",
    "        \n",
    "        # Проверяем, является ли элемент текстовым\n",
    "        if isinstance(element, LTTextContainer):\n",
    "            # Проверяем, находится ли текст в таблице\n",
    "            if table_extraction_flag == False:\n",
    "                # Используем функцию извлечения текста и формата для каждого текстового элемента\n",
    "                (line_text, format_per_line) = text_extraction(element)\n",
    "                # Добавляем текст каждой строки к тексту страницы\n",
    "                page_text.append(line_text)\n",
    "                # Добавляем формат каждой строки, содержащей текст\n",
    "                line_format.append(format_per_line)\n",
    "                page_content.append(line_text)\n",
    "            else:\n",
    "                # Пропускаем текст, находящийся в таблице\n",
    "                pass\n",
    "\n",
    "        # Проверяем элементы на наличие изображений\n",
    "        if isinstance(element, LTFigure):\n",
    "            # Вырезаем изображение из PDF\n",
    "            crop_image(element, pageObj)\n",
    "            # Преобразуем обрезанный pdf в изображение\n",
    "            convert_to_images('cropped_image.pdf')\n",
    "            # Извлекаем текст из изображения\n",
    "            image_text = image_to_text('PDF_image.png')\n",
    "            text_from_images.append(image_text)\n",
    "            page_content.append(image_text)\n",
    "            # Добавляем условное обозначение в списки текста и формата\n",
    "            page_text.append('image')\n",
    "            line_format.append('image')\n",
    "\n",
    "        # Проверяем элементы на наличие таблиц\n",
    "        if isinstance(element, LTRect):\n",
    "            # Если первый прямоугольный элемент\n",
    "            if first_element == True and (table_num+1) <= len(tables):\n",
    "                # Находим ограничивающий прямоугольник таблицы\n",
    "                lower_side = page.bbox[3] - tables[table_num].bbox[3]\n",
    "                upper_side = element.y1 \n",
    "                # Извлекаем информацию из таблицы\n",
    "                table = extract_table(pdf_path, pagenum, table_num)\n",
    "                # Преобразуем информацию таблицы в формат структурированной строки\n",
    "                table_string = table_converter(table)\n",
    "                # Добавляем строку таблицы в список\n",
    "                text_from_tables.append(table_string)\n",
    "                page_content.append(table_string)\n",
    "                # Устанавливаем флаг True, чтобы избежать повторения содержимого\n",
    "                table_extraction_flag = True\n",
    "                # Преобразуем в другой элемент\n",
    "                first_element = False\n",
    "                # Добавляем условное обозначение в списки текста и формата\n",
    "                page_text.append('table')\n",
    "                line_format.append('table')\n",
    "\n",
    "            # Проверяем, извлекли ли мы уже таблицы из этой страницы\n",
    "            if element.y0 >= lower_side and element.y1 <= upper_side:\n",
    "                pass\n",
    "            elif not isinstance(page_elements[i+1][1], LTRect):\n",
    "                table_extraction_flag = False\n",
    "                first_element = True\n",
    "                table_num+=1\n",
    "\n",
    "\n",
    "    # Создаём ключ для словаря\n",
    "    dctkey = 'Page_'+str(pagenum)\n",
    "    # Добавляем список списков как значение ключа страницы\n",
    "    text_per_page[dctkey]= [page_text, line_format, text_from_images,text_from_tables, page_content]\n",
    "\n",
    "# Закрываем объект файла pdf\n",
    "pdfFileObj.close()\n",
    "\n",
    "# Удаляем созданные дополнительные файлы\n",
    "os.remove('cropped_image.pdf')\n",
    "os.remove('PDF_image.png')\n",
    "\n",
    "# Удаляем содержимое страницы\n",
    "result = ''.join(text_per_page['Page_0'][4])\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
